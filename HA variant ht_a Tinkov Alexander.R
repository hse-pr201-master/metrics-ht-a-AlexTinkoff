# Всем привет! Для начала домашки загрузим необходимые пакеты и объясним, для чего они нам нужны. 
library(tidyverse) # манипуляции с данными и графики
library(mfx) # предельные эффекты в логит-пробит моделях
library(rio) # если читать внешний набор данных (в нашем случае это csv)
library(lmtest) # для тестов LR, LM, Wald, ...
library(texreg) # представление результатов в табличках в тех (или в ворд)
library(ivpack) # IV и 2SLS
library(dplyr) # на всякий случай для работы с данными
#зафиксируем seed в соответствии с правилами игры
set.seed(0)
# Загрузим наш файл с данными
data = import("C:/Users/Александр/Desktop/HA Metrics/forestfires.csv")
# Разберёмся в структуре данных
summary(data)

# Посмотрим на саму табличку
view(data)

# Задание №1
# Подготовим данные и избавимся от нулевых значений в объясняемой переменной, как просят в задании
datafltr <- data[data$area > 0, ]

# Повторим визуальный анализ уже для новой таблички
summary(datafltr)
view(datafltr)

# Как известно, площадь пожара area измеряется в ha (к примеру, 1ha/100 = 100 м^2) - мы избавились от нулей, чтобы рассматривать значения больше 100 квадратных метров, однако, как показывает медиана (6.37 при 270 наблюдениях с максимумом на уровне 1090.84) выборка сильно смещена в меньшую сторону, поэтому будем использовать в качестве объясняемой переменной распространнённый способ нормирования log(area), как в исследовании Paulo Cortez и Anibal Moraiz 
arealn = log(datafltr$area)
datafltr <- data.frame(arealn, datafltr)

# Резюмируем - можем заметить, что новая переменная arealn является достаточно упорядоченной переменной, с которой будет просто работать (медиана равняется 1.99742, среднее 2.12741 при максимуме в 6.99562 и минимуме 0.08618)
summary(datafltr)
view(datafltr)

# Провизуализируем и сравним две выборки (новую и старую переменные) - демонстрация того, как помогло преобразование
qplot(data = datafltr, area, xlab = "Area values", ylab = "Number of Area values", main = "Burned Area", binwidth = 1)
qplot(data = datafltr, arealn, xlab = "Arealn values", ylab = "Number of Arealn values", main = "Burned Area, modified with log", binwidth = 1)

# Задание №2
# Для анализа и отбора признаков будем исследовать их коррелированность с area 
install.packages("corrplot")
library("corrplot")
cor(datafltr$area,datafltr$X)
cor(datafltr$area,datafltr$Y)
cor(datafltr$area,datafltr$FFMC)
cor(datafltr$area,datafltr$DMC)
cor(datafltr$area,datafltr$DC)
cor(datafltr$area,datafltr$ISI)
cor(datafltr$area,datafltr$temp)
cor(datafltr$area,datafltr$RH)
cor(datafltr$area,datafltr$wind)

# Для анализа и отбора признаков будем исследовать их коррелированность с arealn
cor(datafltr$arealn,datafltr$X)
cor(datafltr$arealn,datafltr$Y)
cor(datafltr$arealn,datafltr$FFMC)
cor(datafltr$arealn,datafltr$DMC)
cor(datafltr$arealn,datafltr$DC)
cor(datafltr$arealn,datafltr$ISI)
cor(datafltr$arealn,datafltr$temp)
cor(datafltr$arealn,datafltr$RH)
cor(datafltr$arealn,datafltr$wind)

# Преобразуем все категориальные переменные (а именно дни и месяца) в дамми переменные для того, чтобы, во-первых, их можно было бы использовать в качестве регрессоров, а, во-вторых, чтобы можно было работать в численном виде - способ обнаружил на сайте amunategui.github.io
library("caret")
dummy <- dummyVars(" ~ .", data = datafltr)
dumdata <- data.frame(predict(dummy, newdata = datafltr))
summary(dumdata)

# Построим теперь матрицу корреляций для проверки коррелированности между потенциальными регрессорами
mtrx = cor(dumdata)
corrplot(mtrx, method = "square")
# Цветовые квадратики сигнализируют о том, что нужно грамотно изучить природу индексом (ведь корреляция между ними является наивысшая среди всех и колеблется в районе интервала 0,5 - 0,8) 
# FFMC указывает легкость воспламенения топлива, иными словами, вероятность возгорания (на него оказывают влияние температура, уровень относительной влажности, ветер и дождь)
# DMC показывает влажность угля, лежащего под землей. Вероятность возгорания в результате удара молнии (дождь, относительная влажность и ветер оказывают влияние)
# DC показывает степень увлажнения глубоких слоев органического вещества. Свидетельствует о долгосрочных условиях влажности и определяет устойчивость огня к тушению (температура и дождь оказывают влияние)
# ISI показывает скорость распространения огня сразу после возгорания (сочетает FFMC и скорость ветра, чтобы спрогнозировать ожидаемый темп распространения)
# Описание индексных значений взято у Рубцовой Э. Рубцова А. Сухининова А. Ваганова Е. (статья "СИСТЕМНЫЙ АНАЛИЗ ПОГОДНОЙ ПОЖАРНОЙ ОПАСНОСТИ ПРИ ПРОГНОЗИРОВАНИИ КРУПНЫХ ПОЖАРОВ В ЛЕСАХ СИБИРИ") 
# Объясняемая переменная arealn наиболее коррелирована с уровнем с весенними месяцами, с ветром и с днём недели (суббота) - в то время, как изначально заданная переменная area наиболее взаимосвязана с уровнем относительной влажности, температурой и с субботой
# Однако, большинство корреляций (с arealn и с area) принимает околонулевые значения, поэтому будем отбирать признаки не только с опорой на корреляции, но и на здравый смысл
# Пришло время определиться с регрессорами: температура, месяцы (апрель, май, июнь), день недели (суббота), DMC, ISI 
# Температура: логично предположить, что высокая температура - важный фактор, сопутствующий возникновению пожара (ожидаемое влияние - положительное)
# Май: тот месяц, когда температура начинает повышаться, а люди активизируются (шашлыки, пикники - всё это, в основном, в лесу) или уезжают на дачи, где есть поля и леса для прогулок и пикников (ожидаемое влияние - положительное)
# RH: показатель относительной влажности (связан с дождями, грозами), при большой влажности начало пожара маловероятно (ожидаемый эффект - отрицательный)
# ISI: свидетельствует о скорости распространения огня (сильный ветер), что увеличивает потенциальную область пожара (ожидаемый эффект - положительный)
# Ветер: способствует распространению огня и увеличению зоны пожара (ожидаемый эффект - положительный)
# Cуббота: самый активный день отдыха, когда люди активизируются (пикник, шашлыки) и отдыхают на дачах, которые расположены в лесных зонах, а человеческий фактор - одна из причин пожара (ожидаемое влияние - положительное)

# Приведём описательные статистики каждого регрессора
summary(dumdata$temp)
var(dumdata$temp)
summary(dumdata$wind)
var(dumdata$wind)
summary(dumdata$monthmay)
var(dumdata$monthmay)
summary(dumdata$daysat)
var(dumdata$daysat)
summary(dumdata$RH)
var(dumdata$RH)
summary(dumdata$ISI)
var(dumdata$ISI)

# Тест Шапиро-Уилка о нормальности
shapiro.test(dumdata$temp) # p-value меньше любого разумного уровня значимости => H0 отвергается => не соответствует закону нормального распределения 
shapiro.test(dumdata$RH) # p-value меньше любого разумного уровня значимости => H0 отвергается => не соответствует закону нормального распределения
shapiro.test(dumdata$ISI) # p-value меньше любого разумного уровня значимости => H0 отвергается => не соответствует закону нормального распределения
shapiro.test(log(dumdata$temp)) # p-value меньше любого разумного уровня значимости => H0 отвергается => не соответствует закону нормального распределения
shapiro.test(dumdata$wind) # p-value меньше любого разумного уровня значимости => H0 отвергается => не соответствует закону нормального распределения

# Сделаем визуализацию всех регрессоров
qplot(data = dumdata, temp, xlab = "temperature in Celcius", ylab = "number of temperature values", main = "Temperature factor visualization", binwidth = 1)
qplot(data = dumdata, monthmay, xlab = "1 = Fire in May, 0 = No Fire in May", ylab = "number of fires", main = "Fires in May")
qplot(data = dumdata, wind, xlab = "Wind Value", ylab = "Fire area", main = "Wind factor visualisation", binwidth = 1)
qplot(data = dumdata, daysat, xlab = "1 = Fire on Saturday, 0 = No Fire on Saturday", ylab = "number of fires", main = "Fires on Saturdays")
qplot(data = dumdata, RH, xlab = "RH Value", ylab = "number of values", main = "RH factor visualisation", binwidth = 1)
qplot(data = dumdata, ISI, xlab = "ISI Value", ylab = "area of fires", main = "ISI statistics", binwidth = 1)

# Построим ящики с усами для отобранных регрессоров (за исключением дамми, разумеется)
boxplot(dumdata$temp, main = "Temperature factor visualization", xlab = "Temperature in Celcius", col = "blue", border = "black", horizontal = TRUE, notch = FALSE)
boxplot(dumdata$wind, main = "Wind factor visualization", xlab = "Wind values", col = "blue", border = "black", horizontal = TRUE, notch = FALSE)
boxplot(dumdata$RH, main = "RH factor visualization", xlab = "RH Values", col = "blue", border = "black", horizontal = TRUE, notch = FALSE)
boxplot(dumdata$ISI, main = "ISI factor visualization", xlab = "ISI Values", col = "blue", border = "black", horizontal = TRUE, notch = FALSE)

# Выбросы обнаружены в графике Temperature factor visualisation (в меньшую сторону < 4) и RH factor visualisation (в обе стороны <20 и >80) - будем бороться с помощью самого популярного способа (удаление)
dumdata$temp[dumdata$temp < 4] <- NA
na.omit("temp")
dumdata$RH[dumdata$RH < 20] <- NA
dumdata$RH[dumdata$RH > 80] <- NA
na.omit("RH")

# Перейдём к модели
modelfirst <- lm(data = dumdata, arealn ~ temp + wind + daysat + RH + ISI + monthmay)
summary(modelfirst)

# Задание №3
# Проверка на мультиколлинеарность с помощью VIF - все значения VIF меньше 6, поэтому мультиколлинеарности не наблюдаем
library("car")
vif(modelfirst)

# Проверка на мультиколлинеарность с помощью cN - самое наибольшее значение Condition Index оказалось равным 19, что означает, что Condition Number также равняется 19 (меньше 30), поэтому можно спокойно заверить, что мультиколлинеарности не наблюдается
install.packages("olsrr")
library(olsrr)
ols_coll_diag(modelfirst)

# Задание №4
# Оценим модель и проинтерпретируем коэффициенты
summary(modelfirst)
# Значимыми оказались следующие переменные - субботний день и ISI 
# Большинство коэффициентов совпали по знакам с ожиданиями за исключением ISI, так как, возможно, при высокой скорости распространения огня пожарные службы и жители быстрее реагируют и начинают принимать активные действия по предотвращению пожара, поэтому площади сгорает меньше нежели при медленном распространении
library("glmnet")
coeftest(modelfirst) # тестирование коэффициентов
confint(modelfirst) # доверительные интервалы
# Остатки регрессии соответствуют закону нормального распределения - воспользовался тестом Харке-Бера с лекции Демидовой О.А.
library("tseries")
jarque.bera.test(residuals(modelfirst)) # p-value превышает все распространенные уровни значимости, поэтому H0 не отвергается и остатки нормальны

# Задание №5
# доверительный интервал для среднего
predict(modelfirst, newdata = dumdata, interval = "confidence")
# точечный прогноз
predict(modelfirst, newdata = dumdata)
# предиктивный интервал для индивидуального
predict(modelfirst, newdata = dumdata, interval = "prediction")

# Задание №6
# предположение о гетероскедастичности - как мне кажется, достаточно сильный порыв ветра (ураган или шторм) может вызывать развитие и распространение огня, раздувая очаг пожара, то есть сильное колебание дисперсии ошибок возникнет и её непостоянность; по этой же логике сильно засушливый день (высокая температура, низкая влажность) могут создать необходимые условия для горения торфяных месторождений в лесу, вызывая пожар словно некий резкий выброс в разных уголках леса, приводит к сильной непостоянности дисперсии (волатильность)
# регрессор ISI также может стать причиной гетероскедастичности, так как заключает в себе скорость распространения пожара (опять же из-за сильного порыва ветра в засушливую погоду), в такие моменты повышается волатильность (непостоянность дисперсии и её разброс)

# Задание №7
# графический способ определения гетероскедастичности 
qplot(data = dumdata, wind, arealn, main = "wind heteroscedasticity visual checking") # концентрация в единой области, поэтому навряд ли
qplot(data = dumdata, ISI, arealn, main = "ISI heteroscedasticity visual checking") # схожая картинка с ветром
qplot(data = dumdata, temp, arealn, main = "Temperature heteroscedasticity visual checking") # а вот тут, как учили (гетероскедастичность наблюдается)

library("sandwich")
vcov(modelfirst) # оценка ковариационной матрицы

library("dplyr")
library("broom")
install.packages("prettyR")
library("prettyR")
# Тест Голдфелда-Куандта на проверку гетероскедастичности
OrderWind <- dumdata[order(dumdata$wind), ] # поменяем порядок строк
GQ <- lm(data = OrderWind, arealn ~ temp + wind + daysat + RH + ISI + monthmay)
gqtest(GQ, fraction = 0.2) # будем выкидывать 20% из середины выборки, как учил ББ
# ветер оказался гомоскедастичным, так как p-value больше любого разумного уровня значимости, то есть H0 не отвергается

OrderISI <- dumdata[order(dumdata$ISI), ] # поменяем порядок строк
GQ1 <- lm(data = OrderISI, arealn ~ temp + wind + daysat + RH + ISI + monthmay)
gqtest(GQ1, fraction = 0.2)
# логично, что так как ISI является индексом скорости распространения огня (по сути ветер), поэтому как и с ветром наблюдаем гомоскедастичность

OrderTemp <- dumdata[order(dumdata$temp), ] # поменяем порядок строк
GQ2 <- lm(data = OrderTemp, arealn ~ temp + wind + daysat + RH + ISI + monthmay)
gqtest(GQ2, fraction = 0.2)
# в данном случае наблюдается гетероскедастичность, так как p-value очень мал и в связи с этим H0 отверглась - такой результат достаточно ожидаем, так как на картинке это было видно
# мой визуальный анализ подтвердился с помощью теста Голуфелда-Квандта, чему я очень рад

# Задание №8 
# взвешенный МНК


# Задание №9
# робастные ошибки в форме Уайта HC0 - воспользуемся пакетом, который поможет нам посчитать данные ошибки: устойчивая к гетероскедастичности и автокорреляции формула расчёта ковариационной матрицы оценки коэффициента (сначала представляем бету в классическом виде (X'X)^(-1)X'Y, затем заменяем и подставляем в Y = xB + u, получаем оценку беты в таком виде => Var(бета с крышкой) = (X'X)^(-1)X'Var(u)X(X'X)^(-1)). В современном варианте исчисления робастных ошибок в форме Уайта диагональ матрицы корректируется на (1 - леверидж в форме hij)^2. 
vcovHC(modelfirst, type = "HC0")
# робастные ошибки, которые устойчивы к гетероскедастичности
coeftest(modelfirst, vcov = vcovHC(modelfirst, type = "HC0")) # получили p-value, теперь необходимо их сравнить с нашей первоначальной моделью 
# сравнение с МНК
coeftest(modelfirst) # все p-value для всех коэффициентов уменьшились, что было достаточно ожидаемо, также можно заметить, что стало три значимых коэффициентов (при переменных ISI, monthmay и wind) вместо двух прошлых
# так как гетероскедастичность была у переменной temp, то p-value этого коэффициента уменьшилось с 0,52 до 0,48, но коэффициент по-прежнему незначим
# повторим тоже самое и с HC3 - как можно заметить R не хочет с этим справляться, поэтому я обратился к трудам
vcovHC(modelfirst, type = "HC3")
coeftest(modelfirst, vcov = vcovHC(modelfirst, type = "HC3"))
# HC3, HC4 (Long and Ervin 2000, Hayes and Cai 2007) или HC4m (Cribari-Neto and Silva 2011), конечно, являются более хорошим вариантом, однако, как пишут исследователи в своей работе (R может не воспроизводить результаты правильно в случае c HC3 в связи с особой структурой данной, для которых такой современный вид робастных ошибок в форме Уайта не является оптимальным и рекомендуют использовать более простые виды получения робастных ошибок - ввиду этого я решил довериться их совету и использовать HC1, что позволило мне получить нужный результат). По мнению учёных, проблема возникает из-за того, что робастные ошибки HC3 могут возникать смещёнными из-за небольших или умеренно больших выборок, поэтому R вследствие обнаружения такой смещённости не выдаёт полученные значения, защищая исследователя от потенциального неверного хода в научной работе
vcovHC(modelfirst, type = "HC1")
coeftest(modelfirst, vcov = vcovHC(modelfirst, type = "HC1"))
# Хочу сказать спасибо учёным! Действительно, данный вид робастных ошибок также помог и сократил p-value для коэффициентов всех переменных (теперь значимость у 3 коэффициентов)

# Задание №10
#PCA - Метод главных компонент => Отберём рассматриваемые признаки из модели в новый набор данных
datafinal <- data.frame(Temp = dumdata$temp, Wind = dumdata$wind, Daysat = dumdata$daysat, RelHumid = dumdata$RH, ISI = dumdata$ISI, Monthmay = dumdata$monthmay)
view(datafinal)
summary(datafinal)
# обнаружили несуществующие значения NA в столбце RelHumid, они нам будут мешать
# удалим значения NA в новом наборе данных для того, чтобы было возможно реализовать метод главных компонент (самый популярный способ - просто удалить)
datafinal <- na.omit(datafinal)
view(datafinal)
summary(datafinal)
datafinalPCA <- prcomp(datafinal, scale = TRUE)
# Получим первую главную компоненту
PCAfirst <- datafinalPCA$x[, 1]
head(PCAfirst)
# Теперь узнаем, какие веса в первой главной компоненте имеют входящие в неё переменные
varfirst <- datafinalPCA$rotation[, 1]
varfirst
summary(datafinalPCA) # можем заметить, что первая главная компонента объясняет долю дисперсии 31%, вторая главная компонента объясняет долю дисперсии 18,8%, третья главная компонента объясняет долю дисперсии в 17%, четвертая - 15% доля дисперсии, пятая и шестая - 12,45% и 5,4% доли соответственно
PCAsecond <- datafinalPCA$x[, 2]
modelsecond <- lm(data = dumdata, arealn ~ PCAfirst) # в данном случае, у меня PCAfirst не подходит по размерности, так как 262 элемента не равны 270 элементам
modelthird <- lm(data = dumdata, arealn ~ PCAfirst + PCAsecond) #та же история
